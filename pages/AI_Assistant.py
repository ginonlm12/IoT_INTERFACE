import streamlit as st
import openai
import time
import pyttsx3
import speech_recognition as sr
import asyncio
from typing import Any, Dict
from gtts import gTTS
import io
from pydub import AudioSegment
from pydub.playback import play
from db_connect import get_latest_temperature, get_latest_light_percentage, get_statistics_by_date, analyze_on_time
from datetime import datetime, timedelta
from toggle import toggle_light, toggle_fan, read_value
from config import topic, openai_key

time = datetime.now()

# Function to play audio directly
from tempfile import TemporaryFile

def generate_prompt_statistics_report(date="2025-01-02"):
    """
    T·∫°o prompt ƒë·ªÉ b√°o c√°o d·ª±a tr√™n d·ªØ li·ªáu th·ªëng k√™ t·ª´ `get_statistics_by_date`.
    
    Parameters:
    - date: Ng√†y (string d·∫°ng 'YYYY-MM-DD') ƒë·ªÉ l·∫•y d·ªØ li·ªáu

    Returns:
    - Prompt d·∫°ng string
    """
    print("date:", date)
    formatted_date = date.strftime("%Y-%m-%d")
    statistics_df = get_statistics_by_date(formatted_date)
    
    if statistics_df.empty:
        return f"Kh√¥ng c√≥ d·ªØ li·ªáu th·ªëng k√™ cho ng√†y {date}. Vui l√≤ng th·ª≠ l·∫°i v·ªõi ng√†y kh√°c."

    # L·∫•y d·ªØ li·ªáu t·ª´ dataframe
    mean_data = statistics_df.iloc[0][["mean_light", "mean_temp"]]
    min_data = statistics_df.iloc[0][["min_light", "min_temp"]]
    max_data = statistics_df.iloc[0][["max_light", "max_temp"]]
    max_change_data = statistics_df.iloc[0][["max_change_light", "max_change_temp"]]
    fan_on_time = statistics_df.iloc[0]["fan_on_time"]
    led_on_time = statistics_df.iloc[0]["led_on_time"]

    # T√≠nh t·ªïng th·ªùi gian b·∫≠t qu·∫°t v√† ƒë√®n, ∆∞·ªõc t√≠nh c√¥ng su·∫•t
    fan_total, fan_power, fan_max_continuous = analyze_on_time(fan_on_time, "fan")
    led_total, led_power, led_max_continuous = analyze_on_time(led_on_time, "led")

    # X√¢y d·ª±ng n·ªôi dung b√°o c√°o
    prompt = f"B·∫°n l√† tr·ª£ l√Ω Smart Livestock Management System. H√£y ƒë∆∞a ra b√°o c√°o chi ti·∫øt v·ªÅ ng√†y {date} nh∆∞ sau:\n\n"
    prompt += f"1. **Th√¥ng s·ªë trung b√¨nh:**\n"
    prompt += f"   - Nhi·ªát ƒë·ªô: {mean_data['mean_temp']}¬∞C\n"
    prompt += f"   - √Ånh s√°ng: {mean_data['mean_light']}%\n\n"

    prompt += f"2. **Th√¥ng s·ªë t·ªëi thi·ªÉu:**\n"
    prompt += f"   - Nhi·ªát ƒë·ªô: {min_data['min_temp']}¬∞C\n"
    prompt += f"   - √Ånh s√°ng: {min_data['min_light']}%\n\n"

    prompt += f"3. **Th√¥ng s·ªë t·ªëi ƒëa:**\n"
    prompt += f"   - Nhi·ªát ƒë·ªô: {max_data['max_temp']}¬∞C\n"
    prompt += f"   - √Ånh s√°ng: {max_data['max_light']}%\n\n"

    prompt += f"4. **Bi·∫øn ƒë·ªïi l·ªõn nh·∫•t:**\n"
    prompt += f"   - Nhi·ªát ƒë·ªô: {max_change_data['max_change_temp']}¬∞C\n"
    prompt += f"   - √Ånh s√°ng: {max_change_data['max_change_light']}%\n\n"

    prompt += f"5. **NƒÉng l∆∞·ª£ng ti√™u th·ª•:**\n"
    prompt += f"   - Qu·∫°t: {fan_power} Wh\n"
    prompt += f"   - ƒê√®n: {led_power} Wh\n\n"

    prompt += f"6. **Th·ªùi gian b·∫≠t thi·∫øt b·ªã:**\n"
    prompt += f"   - Th·ªùi gian b·∫≠t qu·∫°t: {fan_total} gi√¢y\n"
    prompt += f"   - Th·ªùi gian b·∫≠t ƒë√®n: {led_total} gi√¢y\n"

    prompt += f"7. **Th·ªùi gian b·∫≠t li√™n t·ª•c l√¢u nh·∫•t:**\n"
    prompt += f"   - Qu·∫°t: {fan_max_continuous} gi√¢y\n"
    prompt += f"   - ƒê√®n: {led_max_continuous} gi√¢y\n\n"

    prompt += f"ƒê∆∞a ra k·∫øt lu·∫≠n v√† l·ªùi khuy√™n d·ª±a tr√™n c√°c th√¥ng s·ªë tr√™n."

    return prompt

def play_audio(text: str):
    """Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh gi·ªçng n√≥i v√† ph√°t tr·ª±c ti·∫øp tr√™n Streamlit."""
    tts = gTTS(text, lang="vi")
    with TemporaryFile() as fp:
        tts.write_to_fp(fp)
        fp.seek(0)
        audio = AudioSegment.from_file(fp, format="mp3")
        play(audio)

def speech_to_text_google() -> str:
    """S·ª≠ d·ª•ng Google Speech-to-Text ƒë·ªÉ nh·∫≠n di·ªán ti·∫øng Vi·ªát."""
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        st.write("ƒêang l·∫Øng nghe...")
        audio = recognizer.listen(source, phrase_time_limit=2)
    try:
        return recognizer.recognize_google(audio, language="vi-VN")  # Th√™m `language="vi-VN"`
    except sr.UnknownValueError:
        return "Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i."
    except sr.RequestError as e:
        return f"L·ªói: {e}"

openai.api_key = openai_key
def gpt_response_with_function_calling(prompt: str):
    """Get GPT response and execute function calls."""
    async def get_response():
        response = await openai.ChatCompletion.acreate(
            model="gpt-4-0613",
            messages=[
                {"role": "system", "content": "B·∫°n l√† tr·ª£ l√Ω Smart Livestock Management System ƒë∆∞·ª£c x√¢y d·ª±ng b·ªüi ƒë·ªôi ng≈© ƒë·∫øn t·ª´ ƒê·∫°i h·ªçc B√°ch Khoa H√† N·ªôi l√† Quang, L√¢m, Tu·∫•n, Qu·ªëc Tu·∫•n, ph·∫£n h·ªìi v√† giao ti·∫øp ho√†n to√†n b·∫±ng ti·∫øng Vi·ªát."},
                {"role": "user", "content": prompt},
            ],
            functions=[
                {
                    "name": "get_current_temperature",
                    "description": "Xem nhi·ªát ƒë·ªô hi·ªán t·∫°i v√† ƒë∆∞a ra c·∫£nh b√°o tr·∫°ng th√°i.",
                    "parameters": {"type": "object", "properties": {}}
                },
                {
                    "name": "get_current_light",
                    "description": "Xem ph·∫ßn trƒÉm √°nh s√°ng hi·ªán t·∫°i v√† ƒë∆∞a ra c·∫£nh b√°o tr·∫°ng th√°i.",
                    "parameters": {"type": "object", "properties": {}}
                },
                {
                    "name": "summary_report",
                    "description": "Xem t√≥m t·∫Øt tr·∫°ng th√°i t·ªïng qu√°t c·ªßa h·ªá th·ªëng.",
                    "parameters": {"type": "object", "properties": {}}
                },
                {
                    "name": "toggle_light",
                    "description": "Xem tr·∫°ng th√°i ƒë√®n ho·∫∑c b·∫≠t ho·∫∑c t·∫Øt ƒë√®n.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "status": {"type": "string", "enum": ["xem", "b·∫≠t", "t·∫Øt"]}
                        },
                        "required": ["status"]
                    }
                },
                {
                    "name": "toggle_fan",
                    "description": "Xem tr·∫°ng th√°i qu·∫°t ho·∫∑c b·∫≠t ho·∫∑c t·∫Øt qu·∫°t.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "status": {"type": "string", "enum": ["xem", "b·∫≠t", "t·∫Øt"]}
                        },
                        "required": ["status"]
                    }
                }
            ]
        )
        return response

    result = asyncio.run(get_response())
    function_call = result["choices"][0]["message"].get("function_call")
    if function_call:
        function_name = function_call["name"]
        parameters = function_call.get("arguments", {})
        # G·ªçi h√†m t∆∞∆°ng ·ª©ng
        function_result = function_calling(function_name, eval(parameters))
        
        # T·∫°o m·ªôt prompt m·ªõi ƒë·ªÉ GPT tr·∫£ l·ªùi t·ª´ k·∫øt qu·∫£ h√†m
        follow_up_prompt = f"K·∫øt qu·∫£ c·ªßa {function_name}: {function_result}. H√£y ph·∫£n h·ªìi chi ti·∫øt."
        return gpt_response_with_function_calling(follow_up_prompt)
    else:
        return result["choices"][0]["message"]["content"]

def function_calling(function_name: str, parameters: Dict[str, Any]) -> Any:
    """Th·ª±c hi·ªán ch·ª©c nƒÉng t∆∞∆°ng ·ª©ng."""
    if function_name == "get_current_temperature":
        temperature, time, date = get_latest_temperature()
        string = f"B·∫°n l√† tr·ª£ l√Ω ·∫£o Smart Livestock Management System ƒë∆∞a ra l·ªùi khuy√™n v·ªÅ nhi·ªát ƒë·ªô. Nhi·ªát ƒë·ªô ·ªü th·ªùi ƒëi√™m hi·ªán t·∫°i, {time}, {date} l√† {temperature}¬∞C."
        if temperature > 35:
            return string + f"C·∫£nh b√°o: Nhi·ªát ƒë·ªô qu√° cao!"
        elif temperature < 15:
            return string + f"C·∫£nh b√°o: Nhi·ªát ƒë·ªô qu√° th·∫•p!"
        else:
            return string
    elif function_name == "get_current_light":
        light_percentage, time, date = get_latest_light_percentage()
        string = f"B·∫°n l√† tr·ª£ l√Ω ·∫£o Smart Livestock Management System ƒë∆∞a ra l·ªùi khuy√™n v·ªÅ √°nh s√°ng. √Ånh s√°ng ·ªü th·ªùi ƒëi√™m hi·ªán t·∫°i, {time}, {date} l√† {light_percentage}¬∞C."
        if light_percentage > 90:
            return string + f"C·∫£nh b√°o: √Ånh s√°ng qu√° cao!"
        elif light_percentage < 60:
            return string + f"C·∫£nh b√°o: √Ånh s√°ng qu√° th·∫•p!"
        else:
            return string
    elif function_name == "summary_report":
        return generate_prompt_statistics_report(datetime.today())
    elif function_name == "toggle_light":
        time = datetime.now()
        string = f"B·∫°n l√† tr·ª£ l√Ω ·∫£o Smart Livestock Management System b·∫≠t, t·∫Øt ƒë√®n. Th·ªùi gian hi·ªán t·∫°i l√† {time}."
        status = parameters.get("status")
        if "b·∫≠t" in status:
            toggle_light(1)
            return string  + f"ƒê√®n ƒë√£ ƒë∆∞·ª£c {status}. H√£y th√¥ng b√°o ng∆∞·ªùi d√πng."
        elif "t·∫Øt" in status:
            toggle_light(0)
            return string  + f"ƒê√®n ƒë√£ ƒë∆∞·ª£c {status}. H√£y th√¥ng b√°o ng∆∞·ªùi d√πng."
        else:
            
            value = read_value("V27")
            print(value)
            return f"ƒê√®n ƒëang ·ªü tr·∫°ng th√°i {value}. (0 l√† ƒëang t·∫Øt v√† 1 ƒëang l√† b·∫≠t, c√°c tr·∫°ng th√°i kh√°c l√† l·ªói)"
    elif function_name == "toggle_fan":
        time = datetime.now()
        string = f"B·∫°n l√† tr·ª£ l√Ω ·∫£o Smart Livestock Management System b·∫≠t, t·∫Øt qu·∫°t. Th·ªùi gian hi·ªán t·∫°i l√† {time}."
        status = parameters.get("status")
        if "b·∫≠t" in status:
            toggle_fan(1)
            return string + f"Qu·∫°t ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh ƒë·ªÉ {status} b·∫±ng hi·ªáu l·ªánh.."
        elif "t·∫Øt" in status:
            toggle_fan(0)
            return string + f"Qu·∫°t ƒë√£ ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh ƒë·ªÉ {status} b·∫±ng hi·ªáu l·ªánh.."
        else:
            value = read_value("V26")
            return f"Qu·∫°t ƒëang ·ªü tr·∫°ng th√°i {value}. (0 l√† ƒëang t·∫Øt v√† 1 ƒëang l√† b·∫≠t, c√°c tr·∫°ng th√°i kh√°c l√† l·ªói)"
    
    else:
        return "Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c y√™u c·∫ßu. Vui l√≤ng th·ª≠ l·∫°i."
    
# Initialize session state for conversation history
if "conversation_history" not in st.session_state:
    st.session_state["conversation_history"] = []  # List to store messages

# Function to update conversation history
def update_conversation_history(user_message: str, assistant_response: str):
    st.session_state["conversation_history"].append({"role": "user", "message": user_message})
    st.session_state["conversation_history"].append({"role": "assistant", "message": assistant_response})

# Display conversation history
st.subheader("üó®Ô∏è Conversation History")
with st.container():
    for message in st.session_state["conversation_history"]:
        if message["role"] == "user":
            st.markdown(f"**üßë User:** {message['message']}")
        else:
            st.markdown(f"**ü§ñ Assistant:** {message['message']}")

# Voice Input Button
if st.button("üé§ Ghi L·∫°i Gi·ªçng N√≥i"):
    st.write("ƒêang ghi √¢m... Vui l√≤ng n√≥i r√µ.")
    user_voice = speech_to_text_google()
    
    if user_voice:
        st.success(f"B·∫°n ƒë√£ n√≥i: {user_voice}")
        if user_voice == "Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i.":
            user_voice = "B·∫°n h√£y ƒë√≥ng vai b·∫°n l√† tr·ª£ l√Ω ·∫£o Smart Livestock Management System c√≥ h·ªó tr·ª£ gi·ªçng n√≥i, tuy nhi√™n, do l·ªói kƒ© thu·∫≠t n√™n ch∆∞a th·ªÉ ghi l·∫°i gi·ªçng n√≥i, h√£y tr·∫£ l·ªùi ng∆∞·ªùi d√πng y√™u c·∫ßu h·ªç n√≥i l·∫°i."
        
        # Pass text to GPT model for action inference
        gpt_output = gpt_response_with_function_calling(user_voice)
        
        # Update conversation history
        update_conversation_history(user_voice, gpt_output)
        
        # Display assistant response
        # st.write(f"üß† K·∫øt Qu·∫£ GPT: {gpt_output}")
        
        # Play Response as Voice
        st.markdown("### AI ƒëang tr·∫£ l·ªùi...")
        play_audio(gpt_output)
        st.write(f"üß† K·∫øt Qu·∫£ GPT: {gpt_output}")
    else:
        st.error("Kh√¥ng th·ªÉ nh·∫≠n di·ªán gi·ªçng n√≥i. Vui l√≤ng th·ª≠ l·∫°i.")